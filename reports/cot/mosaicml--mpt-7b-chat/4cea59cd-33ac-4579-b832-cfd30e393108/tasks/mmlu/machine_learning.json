{
    "score": 0.2,
    "model_outputs": [
        {
            "id": 17,
            "question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):\n\n(A) The number of hidden nodes\n(B) The learning rate\n(C) The initial choice of weights\n(D) The use of a constant-term unit input",
            "correct_answer": 0,
            "model_answer": ": \n(A) The number of hidden nodes is the structural assumption that most affects the trade-off between underfitting and overfitting in a neural network. This is because the number of hidden nodes determines the complexity of the model, and a model with too few hidden nodes may not be able to capture the underlying patterns in the data, leading to underfitting. On the other hand, a model with too many hidden nodes may overfit the training data, leading to high variance and poor generalization performance. Therefore, finding the optimal number of hidden nodes is crucial for achieving a good trade-off between underfitting and overfitting.",
            "correct": true
        },
        {
            "id": 72,
            "question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.\n\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True",
            "correct_answer": 1,
            "model_answer": ": Thank you for the question. Statement 1 suggests that neural networks are typically trained on CPUs, not GPUs, which is true. Statement 2 suggests that the ResNet-50 model has over 1 billion parameters, which is also true. Therefore, the answer is (A) True, True.",
            "correct": false
        },
        {
            "id": 108,
            "question": "Which of the following is false?\n\n(A) Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image.\n(B) A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive.\n(C) When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive.\n(D) A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative.",
            "correct_answer": 3,
            "model_answer": ":\n(A) Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image.\n(B) A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive.\n(C) When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive.\n(D) A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative.\nThe answer is (A).",
            "correct": false
        },
        {
            "id": 102,
            "question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?\n\n(A) Bias increase ; Variance increase\n(B) Bias increase ; Variance decrease\n(C) Bias decrease ; Variance increase\n(D) Bias decrease ; Variance decrease",
            "correct_answer": 1,
            "model_answer": ": \nLinear regression models are used to estimate the relationship between a dependent variable and one or more independent variables. When the model is overfitting to the data, it means that it is fitting the noise in the data too closely, rather than capturing the underlying relationship between the variables. \nOne way to prevent overfitting is to add regularization to the model. $\\ell_2$ regularization, also known as Lasso regularization, adds a penalty term to the loss function that encourages the model to have smaller weights. \nAs the $\\ell_2$ regularization coefficient increases, the model will tend to have smaller weights, which can help prevent overfitting. However, this also means that the model will tend to have higher bias, as it is sacrificing some accuracy in order to reduce overfitting. \nThe variance of the model will also tend to decrease as the $\\ell_2$ regularization coefficient increases, as the model is becoming more robust to noise in the data. \nTherefore, the answer is (D) Bias decrease ; Variance decrease.",
            "correct": false
        },
        {
            "id": 97,
            "question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?\n\n(A) P(A | B) * P(B | C) * P(C | A)\n(B) P(C | A, B) * P(A) * P(B)\n(C) P(A, B | C) * P(C)\n(D) P(A | B, C) * P(B | A, C) * P(C | A, B)",
            "correct_answer": 2,
            "model_answer": ": \nTo answer this question, we need to understand what the term \"P(A, B, C)\" represents. It is the probability of the event that all three variables A, B, and C are true simultaneously. \nNow, let's look at the four options given. \nOption (A) states that P(A | B) * P(B | C) * P(C | A) represents the probability of A, B, and C all being true, given that A is true. However, we cannot determine the probability of A, B, and C all being true given that A is true, as that would require additional information about the relationship between A, B, and C. Therefore, option (A) is not equal to P(A, B, C).\nOption (B) states that P(C | A, B) * P(A) * P(B) represents the probability of A, B, and C all being true, given that C is true. However, we cannot determine the probability of A, B, and C all being true given that C is true, as that would require additional information about the relationship between A, B, and C. Therefore, option (B) is not equal to P(A, B, C).\nOption (C) states that P(A, B | C) * P(C) represents the probability of A, B, and C all being true, given that C is true. However, we cannot determine the probability of A, B, and C all being true given that C is true, as that would require additional information about the relationship between A, B, and C. Therefore, option (C) is not equal to P(A, B, C).\nOption (D) states that P(A | B, C) * P(B | A, C) * P(C | A, B) represents the probability of A, B, and C all being true, given that A is true. However, we cannot determine the probability of A, B, and C all being true given that A is true, as that would require additional information about the relationship between A, B, and C. Therefore, option (D) is not equal to P(A, B, C).\nTherefore, none of the options given are equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them. The answer is therefore not provided.",
            "correct": true
        },
        {
            "id": 8,
            "question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?\n\n(A) 2\n(B) 4\n(C) 8\n(D) 16",
            "correct_answer": 2,
            "model_answer": ": \nTo determine the number of independent parameters needed for this Bayesian network, we need to consider the number of conditional dependencies between the variables. In this case, there are three conditional dependencies: H -> U, U <- P, and P <- W. \nTherefore, there are 3 independent parameters needed for this Bayesian network. \nAnswer: (D) 16",
            "correct": false
        },
        {
            "id": 32,
            "question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.\n\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True",
            "correct_answer": 1,
            "model_answer": ": Thank you for the question. Let\u2019s break it down step-by-step.\n\nStatement 1 suggests that mapping the data into a new feature space using a radial basis kernel function may improve the performance of a classification algorithm, such as 1-NN. This is because the new feature space may capture more complex patterns in the data, which may not be apparent in the original space. However, we cannot guarantee that this will always be the case, as the performance of the algorithm depends on many factors.\n\nStatement 2 suggests that the VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM. The VC dimension is a measure of the complexity of a learning algorithm, and it is related to the number of training examples that the algorithm can correctly classify. A Perceptron is a simple algorithm that can only learn linear decision boundaries, while a simple linear SVM can learn more complex decision boundaries. Therefore, it is not surprising that the VC dimension of a Perceptron is smaller than that of a simple linear SVM.",
            "correct": false
        },
        {
            "id": 15,
            "question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.\n\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True",
            "correct_answer": 1,
            "model_answer": ": Statement 1 suggests that the authors of the ResNet paper chose to use Layer Normalization instead of Batch Normalization. This is likely because Layer Normalization is a more efficient and effective way to regularize the network, and it also helps to improve the training stability. Statement 2 suggests that the authors of the DCGAN paper chose to use self-attention instead of traditional convolutional layers to stabilize the training process. This is likely because self-attention allows the network to learn more complex and diverse features, which can help to improve the quality of the generated images. Therefore, the correct answer is (A) True, True.",
            "correct": false
        },
        {
            "id": 63,
            "question": "What are support vectors?\n\n(A) The examples farthest from the decision boundary.\n(B) The only examples necessary to compute f(x) in an SVM.\n(C) The data centroid.\n(D) All the examples that have a non-zero weight \u03b1k in a SVM.",
            "correct_answer": 1,
            "model_answer": ": Support vectors are the examples farthest from the decision boundary in a support vector machine (SVM) algorithm. In other words, they are the examples that are most important in determining the decision boundary. The decision boundary is the line or hyperplane that separates the two classes in the data. The support vectors are the examples that are closest to the decision boundary and have the largest margin, or distance from the boundary. The SVM algorithm uses the support vectors to determine the decision boundary and classify new examples.",
            "correct": false
        },
        {
            "id": 57,
            "question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.\n\n(A) True, True\n(B) False, False\n(C) True, False\n(D) False, True",
            "correct_answer": 3,
            "model_answer": ": Thank you for the question. In order to answer this question, we need to understand the meaning of L2 regularization and L1 regularization, as well as residual connections in neural networks.\n\nL2 regularization, also known as Ridge regression, adds a penalty term to the cost function of a linear model that is proportional to the square of the L2 norm of the model's weights. This means that the model will tend to have smaller weights, which in turn makes the model more sparse. L1 regularization, also known as Lasso regression, adds a penalty term to the cost function of a linear model that is proportional to the L1 norm of the model's weights. This means that the model will tend to have smaller weights, which in turn makes the model more sparse.\n\nResidual connections are a technique used in neural networks that allow the output of one layer to be directly passed through to the next layer without any additional processing. This allows the network to learn more complex features and representations.\n\nBased on these definitions, we can see that statement 1 is true, and statement 2 is also true. Therefore, the answer is (A) True, True.",
            "correct": false
        }
    ]
}