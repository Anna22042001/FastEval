{
    "gsm8k": 0.406,
    "math": 0.096,
    "bbh": {
        "tasks": {
            "date_understanding": 0.37333333333333324,
            "disambiguation_qa": 0.6444444444444444,
            "geometric_shapes": 0.14636363636363636,
            "hyperbaton": 0.7333333333333333,
            "logical_deduction_five_objects": 0.3733333333333333,
            "logical_deduction_seven_objects": 0.3714285714285714,
            "logical_deduction_three_objects": 0.3444444444444444,
            "movie_recommendation": 0.4666666666666667,
            "penguins_in_a_table": 0.47333333333333333,
            "reasoning_about_colored_objects": 0.5465608465608465,
            "ruin_names": 0.2,
            "salient_translation_error_detection": 0.21111111111111117,
            "snarks": 0.5166666666666667,
            "temporal_sequences": 0.2833333333333333,
            "tracking_shuffled_objects_five_objects": 0.3466666666666667,
            "tracking_shuffled_objects_seven_objects": 0.3047619047619048,
            "tracking_shuffled_objects_three_objects": 0.4444444444444444
        },
        "average": 0.39883682766035705
    },
    "mmlu": {
        "tasks": {
            "abstract_algebra": 0.05,
            "anatomy": 0.525,
            "astronomy": 0.45,
            "business_ethics": 0.3,
            "clinical_knowledge": 0.3,
            "college_biology": 0.4,
            "college_chemistry": 0.45,
            "college_computer_science": 0.55,
            "college_mathematics": 0.3,
            "college_medicine": 0.425,
            "college_physics": 0.275,
            "computer_security": 0.375,
            "conceptual_physics": 0.425,
            "econometrics": 0.275,
            "electrical_engineering": 0.325,
            "elementary_mathematics": 0.325,
            "formal_logic": 0.8,
            "global_facts": 0.35,
            "high_school_biology": 0.325,
            "high_school_chemistry": 0.25,
            "high_school_computer_science": 0.75,
            "high_school_european_history": 0.35,
            "high_school_geography": 0.55,
            "high_school_government_and_politics": 0.275,
            "high_school_macroeconomics": 0.6,
            "high_school_mathematics": 0.2,
            "high_school_microeconomics": 0.3,
            "high_school_physics": 0.4,
            "high_school_psychology": 0.425,
            "high_school_statistics": 0.25,
            "high_school_us_history": 0.375,
            "high_school_world_history": 0.25,
            "human_aging": 0.6,
            "human_sexuality": 0.575,
            "international_law": 0.4,
            "jurisprudence": 0.35,
            "logical_fallacies": 0.6,
            "machine_learning": 0.025,
            "management": 0.575,
            "marketing": 0.45,
            "medical_genetics": 0.35,
            "miscellaneous": 0.525,
            "moral_disputes": 0.475,
            "moral_scenarios": 0.275,
            "nutrition": 0.325,
            "philosophy": 0.475,
            "prehistory": 0.475,
            "professional_accounting": 0.2,
            "professional_law": 0.825,
            "professional_medicine": 0.275,
            "professional_psychology": 0.25,
            "public_relations": 0.575,
            "security_studies": 0.35,
            "sociology": 0.55,
            "us_foreign_policy": 0.7,
            "virology": 0.325,
            "world_religions": 0.4
        },
        "average": 0.4057017543859649
    },
    "total": 0.2805077164092644
}