{
    "infiniteloop-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "infiniteloop-match.s1.simple-v0",
            "base_eval": "infiniteloop-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "infiniteloop-match/infiniteloop-match.jsonl"
                    },
                    "key": "infiniteloop-match.s1.simple-v0",
                    "group": "infiniteloop-match"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051420532265BNAQH2",
            "created_at": "2023-05-14 20:53:22.812474"
        },
        "final_report": {
            "accuracy": 0.65
        }
    },
    "test-includes.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "test-includes.s1.simple-v0",
            "base_eval": "test-includes",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl"
                    },
                    "key": "test-includes.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220244K736O4XJ",
            "created_at": "2023-05-14 22:02:44.302571"
        },
        "final_report": {
            "accuracy": 1.0
        }
    },
    "coqa-match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-match.dev.v0",
            "base_eval": "coqa-match",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "coqa/match.jsonl"
                    },
                    "key": "coqa-match.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514201623GHAKQ6DH",
            "created_at": "2023-05-14 20:16:23.937351"
        },
        "final_report": {
            "accuracy": 0.8
        }
    },
    "naughty_strings_graded.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "naughty_strings_graded.test.v1",
            "base_eval": "naughty_strings_graded",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "naughty_strings/security.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "security"
                    },
                    "key": "naughty_strings_graded.test.v1",
                    "group": "naughty_strings"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514195749DOIGBCWT",
            "created_at": "2023-05-14 19:57:49.638318"
        },
        "final_report": {
            "counts/Yes": 10,
            "counts/Unsure": 5,
            "counts/No": 5,
            "score": 0.625
        }
    },
    "stock-options-bear-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-options-bear-call-spread.dev.v0",
            "base_eval": "stock-options-bear-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_bear_call_spread.jsonl"
                    },
                    "key": "stock-options-bear-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205430WCHT5PUT",
            "created_at": "2023-05-14 20:54:30.926030"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "emoji-riddle.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "emoji-riddle.s1.simple-v0",
            "base_eval": "emoji-riddle",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "emoji_riddle/fuzzy_match.jsonl"
                    },
                    "key": "emoji-riddle.s1.simple-v0",
                    "group": "emoji-riddle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514211055WALRH4AA",
            "created_at": "2023-05-14 21:10:55.884976"
        },
        "final_report": {
            "accuracy": 0.35,
            "f1_score": 0.42833333333333334
        }
    },
    "test-fuzzy-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "test-fuzzy-match.s1.simple-v0",
            "base_eval": "test-fuzzy-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl"
                    },
                    "key": "test-fuzzy-match.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220240QWS22OYU",
            "created_at": "2023-05-14 22:02:40.635933"
        },
        "final_report": {
            "accuracy": 0.6666666666666666,
            "f1_score": 0.26406926406926406
        }
    },
    "coqa-closedqa-correct.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-closedqa-correct.dev.v0",
            "base_eval": "coqa-closedqa-correct",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "correctness: Is the answer correct?"
                        }
                    },
                    "key": "coqa-closedqa-correct.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202031UGHCFEK3",
            "created_at": "2023-05-14 20:20:31.575829"
        },
        "final_report": {
            "counts/Y": 8,
            "counts/N": 1,
            "score": 0.8888888888888888
        }
    },
    "stock-option-terms-bear-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-option-terms-bear-call-spread.dev.v0",
            "base_eval": "stock-option-terms-bear-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_bear_call_spread.jsonl"
                    },
                    "key": "stock-option-terms-bear-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142055596WATQZV3",
            "created_at": "2023-05-14 20:55:59.551696"
        },
        "final_report": {
            "accuracy": 0.4166666666666667
        }
    },
    "map-electronic-component-part-to-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "map-electronic-component-part-to-fact.dev.v0",
            "base_eval": "map-electronic-component-part-to-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "map-electronic-component-part-to-fact/samples.jsonl"
                    },
                    "key": "map-electronic-component-part-to-fact.dev.v0",
                    "group": "map-electronic-component-part-to-fact"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202615KIEL4HCD",
            "created_at": "2023-05-14 20:26:15.161494"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "logiqa.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "logiqa.dev.v0",
            "base_eval": "logiqa",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "logiqa/logiqa.jsonl"
                    },
                    "key": "logiqa.dev.v0",
                    "group": "logiqa"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203403WSTAGFJX",
            "created_at": "2023-05-14 20:34:03.466169"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "reverse-string.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "reverse-string.s1.simple-v0",
            "base_eval": "reverse-string",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "reverse_string/reverse_string.jsonl"
                    },
                    "key": "reverse-string.s1.simple-v0",
                    "group": "reverse-string"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514200258F5KPOU6S",
            "created_at": "2023-05-14 20:02:58.340853"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "stock-option-terms-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-option-terms-iron-condor-spread.dev.v0",
            "base_eval": "stock-option-terms-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_iron_condor_spread.jsonl"
                    },
                    "key": "stock-option-terms-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205657Y63GM53U",
            "created_at": "2023-05-14 20:56:57.761608"
        },
        "final_report": {
            "accuracy": 0.7
        }
    },
    "compare-countries-area.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "compare-countries-area.dev.v0",
            "base_eval": "compare-countries-area",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "compare-countries-area/samples.jsonl"
                    },
                    "key": "compare-countries-area.dev.v0",
                    "group": "compare-countries-area"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142111395ZJKB4B6",
            "created_at": "2023-05-14 21:11:39.898713"
        },
        "final_report": {
            "accuracy": 0.3
        }
    },
    "mg-humor-people_jp.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "mg-humor-people_jp.dev.v0",
            "base_eval": "mg-humor-people_jp",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/humor_people_jp.jsonl",
                        "eval_type": "cot_classify_jp",
                        "modelgraded_spec": "humor_jp"
                    },
                    "key": "mg-humor-people_jp.dev.v0",
                    "group": "test-modelgraded-generated"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514213651DKKPMSR5",
            "created_at": "2023-05-14 21:36:51.612612"
        },
        "final_report": {
            "counts/3": 14,
            "counts/1": 3,
            "counts/2": 3,
            "score": 2.55
        }
    },
    "joke-fruits-expl-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-fruits-expl-meta.dev.v0",
            "base_eval": "joke-fruits-expl-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "classify_cot",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-expl-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210336DFCG4K4R",
            "created_at": "2023-05-14 21:03:36.806899"
        },
        "final_report": {
            "counts/Yes": 5,
            "counts/Unsure": 5,
            "score": 0.75,
            "metascore": 0.5
        }
    },
    "born-first.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "born-first.dev.v0",
            "base_eval": "born-first",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "born_first/born_first.jsonl"
                    },
                    "key": "born-first.dev.v0",
                    "group": "born-first"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514214358AOFZV7WE",
            "created_at": "2023-05-14 21:43:58.509036"
        },
        "final_report": {
            "accuracy": 0.55
        }
    },
    "test-includes-ignore-case.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "test-includes-ignore-case.s1.simple-v0",
            "base_eval": "test-includes-ignore-case",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl",
                        "ignore_case": true
                    },
                    "key": "test-includes-ignore-case.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220248YLOFMKXL",
            "created_at": "2023-05-14 22:02:48.794479"
        },
        "final_report": {
            "accuracy": 1.0
        }
    },
    "sort-numbers.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "sort-numbers.s1.simple-v0",
            "base_eval": "sort-numbers",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "sort_numeric/samples.jsonl"
                    },
                    "key": "sort-numbers.s1.simple-v0",
                    "group": "sort-numeric"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210956I6465XMO",
            "created_at": "2023-05-14 21:09:56.510731"
        },
        "final_report": {
            "accuracy": 0.65
        }
    },
    "match_banking77.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "match_banking77.test.v1",
            "base_eval": "match_banking77",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "banking77/samples.jsonl"
                    },
                    "key": "match_banking77.test.v1",
                    "group": "banking77"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220756AR424PKG",
            "created_at": "2023-05-14 22:07:56.702507"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "dutch-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "dutch-lexicon.dev.v0",
            "base_eval": "dutch-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "dutch-lexicon/samples.jsonl"
                    },
                    "key": "dutch-lexicon.dev.v0",
                    "group": "dutch-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514195611GVJHQY7A",
            "created_at": "2023-05-14 19:56:11.157490"
        },
        "final_report": {
            "accuracy": 0.85
        }
    },
    "coqa-fact-expl.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-fact-expl.dev.v0",
            "base_eval": "coqa-fact-expl",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "eval_type": "classify_cot",
                        "modelgraded_spec": "fact"
                    },
                    "key": "coqa-fact-expl.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514201851YKGTZNFO",
            "created_at": "2023-05-14 20:18:51.442860"
        },
        "final_report": {
            "counts/A": 7,
            "counts/D": 2
        }
    },
    "escher-sentences.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "escher-sentences.dev.v0",
            "base_eval": "escher-sentences",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "escher_sentences/samples.jsonl"
                    },
                    "key": "escher-sentences.dev.v0",
                    "group": "escher-sentences"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142028254ZUOIHSN",
            "created_at": "2023-05-14 20:28:25.333751"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "rap-people-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "rap-people-vs-fruits.dev.v0",
            "base_eval": "rap-people-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_people_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-people-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514212909PPFHNUAX",
            "created_at": "2023-05-14 21:29:09.749846"
        },
        "final_report": {
            "counts/Yes": 7,
            "counts/No": 2,
            "score": 0.7777777777777778
        }
    },
    "test-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "test-match.s1.simple-v0",
            "base_eval": "test-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_match/samples.jsonl"
                    },
                    "key": "test-match.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220238YEYLEMPY",
            "created_at": "2023-05-14 22:02:38.643049"
        },
        "final_report": {
            "accuracy": 1.0
        }
    },
    "which-is-heavier.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "which-is-heavier.dev.v0",
            "base_eval": "which-is-heavier",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "which_is_heavier/which_is_heavier.jsonl"
                    },
                    "key": "which-is-heavier.dev.v0",
                    "group": "which-is-heavier"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203613QV3NZA4J",
            "created_at": "2023-05-14 20:36:13.055655"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "bulgarian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "bulgarian-lexicon.dev.v0",
            "base_eval": "bulgarian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bulgarian-lexicon/samples.jsonl"
                    },
                    "key": "bulgarian-lexicon.dev.v0",
                    "group": "bulgarian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203108NCK36X4O",
            "created_at": "2023-05-14 20:31:08.236589"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "swedish-spelling.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "swedish-spelling.dev.v0",
            "base_eval": "swedish-spelling",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "swedish-spelling/samples.jsonl"
                    },
                    "key": "swedish-spelling.dev.v0",
                    "group": "swedish-spelling"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202739ERD3PCGV",
            "created_at": "2023-05-14 20:27:39.220106"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "japanese-national-medical-exam01.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "japanese-national-medical-exam01.dev.v0",
            "base_eval": "japanese-national-medical-exam01",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese-national-medical-exam01/japanese-national-medical-exam01.jsonl"
                    },
                    "key": "japanese-national-medical-exam01.dev.v0",
                    "group": "japanese-national-medical-exam01"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142002492GGAV4EC",
            "created_at": "2023-05-14 20:02:49.788339"
        },
        "final_report": {
            "accuracy": 0.4666666666666667
        }
    },
    "medmcqa.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "medmcqa.dev.v0",
            "base_eval": "medmcqa",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "medmcqa/samples.jsonl"
                    },
                    "key": "medmcqa.dev.v0",
                    "group": "medmcqa"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203521IXBCVOTN",
            "created_at": "2023-05-14 20:35:21.337418"
        },
        "final_report": {
            "accuracy": 0.65
        }
    },
    "bitwise.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "bitwise.dev.v0",
            "base_eval": "bitwise",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bitwise/samples.jsonl"
                    },
                    "key": "bitwise.dev.v0",
                    "group": "bitwise"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514213636SF2LKZUU",
            "created_at": "2023-05-14 21:36:36.938522"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "computer-science-problems.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "computer-science-problems.s1.simple-v0",
            "base_eval": "computer-science-problems",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_comp_sci/questions.jsonl"
                    },
                    "key": "computer-science-problems.s1.simple-v0",
                    "group": "test-comp-sci"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514200230RYONFXV6",
            "created_at": "2023-05-14 20:02:30.503916"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "russian-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "russian-rhyme.v0",
            "base_eval": "russian-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "russian-rhyme/samples.jsonl"
                    },
                    "key": "russian-rhyme.v0",
                    "group": "russian-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142012384E3KZ7MS",
            "created_at": "2023-05-14 20:12:38.827158"
        },
        "final_report": {
            "accuracy": 0.5294117647058824,
            "f1_score": 0.24411764705882355
        }
    },
    "number-pattern.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "number-pattern.dev.v0",
            "base_eval": "number-pattern",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "number_pattern/samples.jsonl"
                    },
                    "key": "number-pattern.dev.v0",
                    "group": "number-pattern"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142011152KUOMI5J",
            "created_at": "2023-05-14 20:11:15.010312"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "chess-piece-count.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "chess-piece-count.s1.simple-v0",
            "base_eval": "chess-piece-count",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "chess_piece_count/fuzzy_match.jsonl"
                    },
                    "key": "chess-piece-count.s1.simple-v0",
                    "group": "chess-piece-count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203121YP7OSKH5",
            "created_at": "2023-05-14 20:31:21.550351"
        },
        "final_report": {
            "accuracy": 0.2,
            "f1_score": 0.04166666666666667
        }
    },
    "russian_medical.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "russian_medical.dev.v0",
            "base_eval": "russian_medical",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian_medical/samples.jsonl"
                    },
                    "key": "russian_medical.dev.v0",
                    "group": "russian_medical"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514201209FEHENINI",
            "created_at": "2023-05-14 20:12:09.721677"
        },
        "final_report": {
            "accuracy": 0.6
        }
    },
    "chess.match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "chess.match.dev.v0",
            "base_eval": "chess",
            "split": "match",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "chess/match.jsonl"
                    },
                    "key": "chess.match.dev.v0",
                    "group": "chess"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205254QM5ZTJMI",
            "created_at": "2023-05-14 20:52:54.943011"
        },
        "final_report": {
            "accuracy": 0.3,
            "f1_score": 0.06666666666666667
        }
    },
    "regex.match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "regex.match.dev.v0",
            "base_eval": "regex",
            "split": "match",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "regex-match/samples.jsonl"
                    },
                    "key": "regex.match.dev.v0",
                    "group": "regex-match"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514221238PTUUNFSK",
            "created_at": "2023-05-14 22:12:38.159429"
        },
        "final_report": {
            "accuracy": 0.8
        }
    },
    "mendelian_inheritance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "mendelian_inheritance.dev.v0",
            "base_eval": "mendelian_inheritance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "mendelian_inheritance/samples.jsonl"
                    },
                    "key": "mendelian_inheritance.dev.v0",
                    "group": "mendelian_inheritance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514211108S7NMH72Q",
            "created_at": "2023-05-14 21:11:08.533804"
        },
        "final_report": {
            "accuracy": 0.4375
        }
    },
    "stock-option-terms-bull-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-option-terms-bull-call-spread.dev.v0",
            "base_eval": "stock-option-terms-bull-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_bull_call_spread.jsonl"
                    },
                    "key": "stock-option-terms-bull-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205607L4VPQTV4",
            "created_at": "2023-05-14 20:56:07.233676"
        },
        "final_report": {
            "accuracy": 0.625
        }
    },
    "moral_exceptQA.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "moral_exceptQA.test.v1",
            "base_eval": "moral_exceptQA",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "moral_exceptQA/samples.jsonl"
                    },
                    "key": "moral_exceptQA.test.v1",
                    "group": "moral_exceptQA"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514214422HEMWJ5PN",
            "created_at": "2023-05-14 21:44:22.032246"
        },
        "final_report": {
            "accuracy": 0.8
        }
    },
    "number-reading.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "number-reading.dev.v0",
            "base_eval": "number-reading",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "number_reading/number_reading.jsonl"
                    },
                    "key": "number-reading.dev.v0",
                    "group": "number-reading"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202603WHGXYLX5",
            "created_at": "2023-05-14 20:26:03.911442"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "loss-logic-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "loss-logic-fact.dev.v0",
            "base_eval": "loss-logic-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "loss_logic/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "loss-logic-fact.dev.v0",
                    "group": "loss-logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142211306KK4SVVJ",
            "created_at": "2023-05-14 22:11:30.480206"
        },
        "final_report": {
            "counts/B": 1,
            "counts/A": 3,
            "counts/D": 1
        }
    },
    "russian-nlp-tasks.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "russian-nlp-tasks.dev.v0",
            "base_eval": "russian-nlp-tasks",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian-nlp-tasks/samples.jsonl"
                    },
                    "key": "russian-nlp-tasks.dev.v0",
                    "group": "russian-nlp-tasks"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142035426BEZHPNW",
            "created_at": "2023-05-14 20:35:42.729142"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "stock-option-terms-iron-butterfly-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-option-terms-iron-butterfly-spread.dev.v0",
            "base_eval": "stock-option-terms-iron-butterfly-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_iron_butterfly_spread.jsonl"
                    },
                    "key": "stock-option-terms-iron-butterfly-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205613ZBSXSOSQ",
            "created_at": "2023-05-14 20:56:13.133161"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "lat_long_identify.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "lat_long_identify.dev.v0",
            "base_eval": "lat_long_identify",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "lat_long_identify/samples.jsonl"
                    },
                    "key": "lat_long_identify.dev.v0",
                    "group": "lat_long_identify"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514200913YTXFJWO4",
            "created_at": "2023-05-14 20:09:13.145541"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "pattern_identification.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "pattern_identification.dev.v0",
            "base_eval": "pattern_identification",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "pattern_identification/samples.v0.jsonl"
                    },
                    "key": "pattern_identification.dev.v0",
                    "group": "pattern_identification"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514195559UT5BY6SP",
            "created_at": "2023-05-14 19:55:59.609346"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "hindi_upsc.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "hindi_upsc.dev.v0",
            "base_eval": "hindi_upsc",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "hindi_upsc/samples.jsonl"
                    },
                    "key": "hindi_upsc.dev.v0",
                    "group": "hindi_upsc"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220325ITO7NTV5",
            "created_at": "2023-05-14 22:03:25.945746"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "japanese_driving_license.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "japanese_driving_license.s1.simple-v0",
            "base_eval": "japanese_driving_license",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese_driving_license/samples.jsonl"
                    },
                    "key": "japanese_driving_license.s1.simple-v0",
                    "group": "japanese_driving_license"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142057245D6IN64E",
            "created_at": "2023-05-14 20:57:24.880195"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "belarusian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "belarusian-lexicon.dev.v0",
            "base_eval": "belarusian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_lexicon/samples.jsonl"
                    },
                    "key": "belarusian-lexicon.dev.v0",
                    "group": "belarusian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142009267OGO3F64",
            "created_at": "2023-05-14 20:09:26.466416"
        },
        "final_report": {
            "accuracy": 0.45
        }
    },
    "diagrammatic_logic.dev.v2.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "diagrammatic_logic.dev.v2",
            "base_eval": "diagrammatic_logic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "diagrammatic_logic/samples.jsonl"
                    },
                    "key": "diagrammatic_logic.dev.v2",
                    "group": "diagrammatic_logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220832N644OYVF",
            "created_at": "2023-05-14 22:08:32.318489"
        },
        "final_report": {
            "accuracy": 0.55
        }
    },
    "logic-statements.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "logic-statements.dev.v0",
            "base_eval": "logic-statements",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "logic-statements/logic-statements.jsonl"
                    },
                    "key": "logic-statements.dev.v0",
                    "group": "logic-statements"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142211033Y5MKW6N",
            "created_at": "2023-05-14 22:11:03.506621"
        },
        "final_report": {
            "accuracy": 0.05,
            "f1_score": 0.05
        }
    },
    "formal-logic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "formal-logic.dev.v0",
            "base_eval": "formal-logic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "formal_logic/formal_logic_expressions.jsonl"
                    },
                    "key": "formal-logic.dev.v0",
                    "group": "formal_logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142008117Q67QMRS",
            "created_at": "2023-05-14 20:08:11.246699"
        },
        "final_report": {
            "accuracy": 0.9
        }
    },
    "bigrams.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "bigrams.dev.v0",
            "base_eval": "bigrams",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bigrams/samples.jsonl"
                    },
                    "key": "bigrams.dev.v0",
                    "group": "bigrams"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051420104142FRY6U7",
            "created_at": "2023-05-14 20:10:41.596368"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "joke-fruits-ans-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-fruits-ans-meta.dev.v0",
            "base_eval": "joke-fruits-ans-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "classify",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-ans-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051421042545RPLYGO",
            "created_at": "2023-05-14 21:04:25.534986"
        },
        "final_report": {
            "counts/Yes": 5,
            "counts/Unsure": 4,
            "counts/No": 1,
            "score": 0.7,
            "metascore": 0.6
        }
    },
    "algebra-word-problems.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "algebra-word-problems.s1.simple-v0",
            "base_eval": "algebra-word-problems",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "algebra_word_problems/samples.jsonl"
                    },
                    "key": "algebra-word-problems.s1.simple-v0",
                    "group": "algebra-word-problems"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220753BFQ4G5FN",
            "created_at": "2023-05-14 22:07:53.301821"
        },
        "final_report": {
            "accuracy": 0.3333333333333333
        }
    },
    "illinois-law.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "illinois-law.v0",
            "base_eval": "illinois-law",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "illinois-law/samples.jsonl"
                    },
                    "key": "illinois-law.v0",
                    "group": "illinois-law"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051422073436KQFL4V",
            "created_at": "2023-05-14 22:07:34.358146"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "stock-options-inverse-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-options-inverse-iron-condor-spread.dev.v0",
            "base_eval": "stock-options-inverse-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_inverse_iron_condor_spread.jsonl"
                    },
                    "key": "stock-options-inverse-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205537GGSX7XSO",
            "created_at": "2023-05-14 20:55:37.374628"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "crepe.dev.v2.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "crepe.dev.v2",
            "base_eval": "crepe",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "crepe/samples.jsonl"
                    },
                    "key": "crepe.dev.v2",
                    "group": "crepe"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203236XQIZGE4B",
            "created_at": "2023-05-14 20:32:36.698740"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "determinant.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "determinant.test.v1",
            "base_eval": "determinant",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "determinant/samples.jsonl"
                    },
                    "key": "determinant.test.v1",
                    "group": "determinant"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220406TRS5DV7Z",
            "created_at": "2023-05-14 22:04:06.935103"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "convert-hex-hsl-lightness.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "convert-hex-hsl-lightness.dev.v0",
            "base_eval": "convert-hex-hsl-lightness",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "convert-hex-hsl-lightness/samples.jsonl"
                    },
                    "key": "convert-hex-hsl-lightness.dev.v0",
                    "group": "convert-hex-hsl-lightness"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220803QOZFW3Q4",
            "created_at": "2023-05-14 22:08:03.545631"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "multi-step-equations.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "multi-step-equations.dev.v0",
            "base_eval": "multi-step-equations",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "multi-step-equations/samples.jsonl"
                    },
                    "key": "multi-step-equations.dev.v0",
                    "group": "multi-step-equations"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210857C2SWNYFR",
            "created_at": "2023-05-14 21:08:57.338738"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "knot-theory-unknotting-problem.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "knot-theory-unknotting-problem.dev.v0",
            "base_eval": "knot-theory-unknotting-problem",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "knot-theory/knot-theory-unknotting-problems.jsonl"
                    },
                    "key": "knot-theory-unknotting-problem.dev.v0",
                    "group": "knot-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205818BFXNVSVK",
            "created_at": "2023-05-14 20:58:18.836942"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "brazilian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "brazilian-lexicon.dev.v0",
            "base_eval": "brazilian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "brazilian-lexicon/samples.jsonl"
                    },
                    "key": "brazilian-lexicon.dev.v0",
                    "group": "brazilian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205311LNVQABCR",
            "created_at": "2023-05-14 20:53:11.750395"
        },
        "final_report": {
            "accuracy": 0.55
        }
    },
    "simple-knowledge-mongolian.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "simple-knowledge-mongolian.dev.v0",
            "base_eval": "simple-knowledge-mongolian",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "simple-knowledge-mongolian/samples.v0.jsonl"
                    },
                    "key": "simple-knowledge-mongolian.dev.v0",
                    "group": "simple-knowledge-mongolian"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220307YSCQZK6H",
            "created_at": "2023-05-14 22:03:07.596293"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "knot-theory-unknotting-number.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "knot-theory-unknotting-number.dev.v0",
            "base_eval": "knot-theory-unknotting-number",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "knot-theory/knot-theory-unknotting-numbers.jsonl"
                    },
                    "key": "knot-theory-unknotting-number.dev.v0",
                    "group": "knot-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210037WE6TY6NV",
            "created_at": "2023-05-14 21:00:37.334554"
        },
        "final_report": {
            "accuracy": 0.3
        }
    },
    "complex-replace-characters.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "complex-replace-characters.dev.v0",
            "base_eval": "complex-replace-characters",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "complex_replace_characters/samples.jsonl"
                    },
                    "key": "complex-replace-characters.dev.v0",
                    "group": "complex-replace-characters"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210908QFLRJ3AG",
            "created_at": "2023-05-14 21:09:08.225950"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "anagrams.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "anagrams.test.v1",
            "base_eval": "anagrams",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "few_shot_jsonl": "anagrams/fewshot.jsonl",
                        "num_few_shot": 5,
                        "samples_jsonl": "anagrams/samples.jsonl"
                    },
                    "key": "anagrams.test.v1",
                    "group": "anagrams"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203215TILG4Q5Y",
            "created_at": "2023-05-14 20:32:15.048631"
        },
        "final_report": {
            "accuracy": 0.45
        }
    },
    "hand_ranks.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "hand_ranks.test.v1",
            "base_eval": "hand_ranks",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "poker_hand_ranks/full_samples.jsonl"
                    },
                    "key": "hand_ranks.test.v1",
                    "group": "poker_hand_ranks"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204920TPHY3VJH",
            "created_at": "2023-05-14 20:49:20.589184"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "stock-option-terms-inverse-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-option-terms-inverse-iron-condor-spread.dev.v0",
            "base_eval": "stock-option-terms-inverse-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_option_terms_inverse_iron_condor_spread.jsonl"
                    },
                    "key": "stock-option-terms-inverse-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205711P6RS6TDI",
            "created_at": "2023-05-14 20:57:11.621976"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "joke-fruits-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-fruits-meta.dev.v0",
            "base_eval": "joke-fruits-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210304CH4REWPF",
            "created_at": "2023-05-14 21:03:04.499524"
        },
        "final_report": {
            "counts/Yes": 5,
            "counts/No": 5,
            "score": 0.5,
            "metascore": 1.0
        }
    },
    "utility_price_parsing.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "utility_price_parsing.dev.v0",
            "base_eval": "utility_price_parsing",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "utility_price_parsing/samples.jsonl"
                    },
                    "key": "utility_price_parsing.dev.v0",
                    "group": "utility_price_parsing"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202847UTFY3AEB",
            "created_at": "2023-05-14 20:28:47.904222"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "rap-animals-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "rap-animals-vs-fruits.dev.v0",
            "base_eval": "rap-animals-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_animals_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-animals-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142121567LDMEWQR",
            "created_at": "2023-05-14 21:21:56.966159"
        },
        "final_report": {
            "counts/Yes": 8,
            "counts/No": 1,
            "score": 0.8888888888888888
        }
    },
    "ukraine-eit.val.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "ukraine-eit.val.v0",
            "base_eval": "ukraine-eit",
            "split": "val",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "ukraine_eit/samples.jsonl"
                    },
                    "key": "ukraine-eit.val.v0",
                    "group": "ukraine-eit"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514203010FA5K3TFG",
            "created_at": "2023-05-14 20:30:10.908021"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "hebrew-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "hebrew-rhyme.v0",
            "base_eval": "hebrew-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "hebrew_rhyme/samples.jsonl"
                    },
                    "key": "hebrew-rhyme.v0",
                    "group": "hebrew-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514221305BERXRK4Q",
            "created_at": "2023-05-14 22:13:05.780623"
        },
        "final_report": {
            "accuracy": 0.6,
            "f1_score": 0.3936111111111111
        }
    },
    "three-pt-mapping.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "three-pt-mapping.dev.v0",
            "base_eval": "three-pt-mapping",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "three-pt-mapping/three_pt_mapping.jsonl"
                    },
                    "key": "three-pt-mapping.dev.v0",
                    "group": "three-pt-mapping"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202836IEHX7N2R",
            "created_at": "2023-05-14 20:28:36.704728"
        },
        "final_report": {
            "accuracy": 0.3
        }
    },
    "joke-fruits-likert.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-fruits-likert.dev.v0",
            "base_eval": "joke-fruits-likert",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor_likert"
                    },
                    "key": "joke-fruits-likert.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210201F53JDMJ7",
            "created_at": "2023-05-14 21:02:01.448975"
        },
        "final_report": {
            "counts/5": 3,
            "counts/1": 5,
            "counts/2": 1,
            "counts/3": 1,
            "score": 2.5
        }
    },
    "invoices.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "invoices.dev.v0",
            "base_eval": "invoices",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "invoices/match.jsonl"
                    },
                    "key": "invoices.dev.v0",
                    "group": "invoices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205753VZHAFRY7",
            "created_at": "2023-05-14 20:57:53.508459"
        },
        "final_report": {
            "accuracy": 0.45
        }
    },
    "taxes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "taxes.dev.v0",
            "base_eval": "taxes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "taxes/samples.jsonl"
                    },
                    "key": "taxes.dev.v0",
                    "group": "taxes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220655H75CCZCJ",
            "created_at": "2023-05-14 22:06:55.073282"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "coqa-closedqa-relevance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-closedqa-relevance.dev.v0",
            "base_eval": "coqa-closedqa-relevance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "relevance: Is the submission referring to a real quote from the text?"
                        }
                    },
                    "key": "coqa-closedqa-relevance.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202138JCE43U6K",
            "created_at": "2023-05-14 20:21:38.772000"
        },
        "final_report": {
            "counts/Y": 9,
            "score": 1.0
        }
    },
    "categorize-with-distractors.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "categorize-with-distractors.dev.v0",
            "base_eval": "categorize-with-distractors",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "categorize_with_distractors/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "categorize-with-distractors.dev.v0",
                    "group": "categorize_with_distractors"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514201327ZHYAC6VI",
            "created_at": "2023-05-14 20:13:27.567486"
        },
        "final_report": {
            "counts/A": 19,
            "counts/D": 1
        }
    },
    "fcc_amateur_extra.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "fcc_amateur_extra.dev.v0",
            "base_eval": "fcc_amateur_extra",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "fcc_amateur_extra/samples.jsonl"
                    },
                    "key": "fcc_amateur_extra.dev.v0",
                    "group": "fcc_amateur_extra"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142136116OQG6ZXG",
            "created_at": "2023-05-14 21:36:11.401662"
        },
        "final_report": {
            "accuracy": 0.55
        }
    },
    "emotional-intelligence.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "emotional-intelligence.dev.v0",
            "base_eval": "emotional-intelligence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "emotional-intelligence/samples.jsonl"
                    },
                    "key": "emotional-intelligence.dev.v0",
                    "group": "emotional-intelligence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204942QENGDICJ",
            "created_at": "2023-05-14 20:49:42.715389"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "naughty_strings.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "naughty_strings.test.v1",
            "base_eval": "naughty_strings",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "naughty_strings/samples.jsonl"
                    },
                    "key": "naughty_strings.test.v1",
                    "group": "naughty_strings"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514195653ML56RPM3",
            "created_at": "2023-05-14 19:56:53.397534"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "coqa-closedqa-conciseness.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-closedqa-conciseness.dev.v0",
            "base_eval": "coqa-closedqa-conciseness",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "conciseness: Is the answer concise and to the point?"
                        }
                    },
                    "key": "coqa-closedqa-conciseness.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142022492NJAPGO7",
            "created_at": "2023-05-14 20:22:49.369304"
        },
        "final_report": {
            "counts/Y": 7,
            "counts/N": 2,
            "score": 0.7777777777777778
        }
    },
    "unified-patch.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "unified-patch.dev.v0",
            "base_eval": "unified-patch",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "unified_patch/samples.jsonl"
                    },
                    "key": "unified-patch.dev.v0",
                    "group": "unified-patch"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220842QK6AHXSL",
            "created_at": "2023-05-14 22:08:42.718218"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "joke-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-fruits.dev.v0",
            "base_eval": "joke-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor"
                    },
                    "key": "joke-fruits.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210101MVBSDO44",
            "created_at": "2023-05-14 21:01:01.782564"
        },
        "final_report": {
            "counts/Yes": 5,
            "counts/No": 5,
            "score": 0.5
        }
    },
    "actors-sequence.dev.match-v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "actors-sequence.dev.match-v1",
            "base_eval": "actors-sequence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "actors-sequence/samples.jsonl"
                    },
                    "key": "actors-sequence.dev.match-v1",
                    "group": "actors-sequence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514214434DULDICHS",
            "created_at": "2023-05-14 21:44:34.896158"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "forth-stack-sim-basic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "forth-stack-sim-basic.dev.v0",
            "base_eval": "forth-stack-sim-basic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/basic_samples.jsonl"
                    },
                    "key": "forth-stack-sim-basic.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202516R5JUTAXU",
            "created_at": "2023-05-14 20:25:16.975597"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "stock-options-inverse-iron-butterfly-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-options-inverse-iron-butterfly-spread.dev.v0",
            "base_eval": "stock-options-inverse-iron-butterfly-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_inverse_iron_butterfly_spread.jsonl"
                    },
                    "key": "stock-options-inverse-iron-butterfly-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205451HWWEIIEC",
            "created_at": "2023-05-14 20:54:51.520615"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "joke-animals-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "joke-animals-vs-fruits.dev.v0",
            "base_eval": "joke-animals-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/joke_animals_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "joke-animals-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514211344U6PILML4",
            "created_at": "2023-05-14 21:13:44.346632"
        },
        "final_report": {
            "counts/No": 3,
            "counts/Yes": 6,
            "score": 0.6666666666666666
        }
    },
    "logic-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "logic-fact.dev.v0",
            "base_eval": "logic-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "logic/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "logic-fact.dev.v0",
                    "group": "logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142036274NSF4BLO",
            "created_at": "2023-05-14 20:36:27.711822"
        },
        "final_report": {
            "counts/A": 8,
            "counts/D": 2
        }
    },
    "finance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "finance.dev.v0",
            "base_eval": "finance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "finance/credit.jsonl"
                    },
                    "key": "finance.dev.v0",
                    "group": "finance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204935R446MEG7",
            "created_at": "2023-05-14 20:49:35.862374"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "cube-pack.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "cube-pack.dev.v0",
            "base_eval": "cube-pack",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "cube-pack/samples.jsonl"
                    },
                    "key": "cube-pack.dev.v0",
                    "group": "cube-pack"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514200215YUR3BYSY",
            "created_at": "2023-05-14 20:02:15.199913"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "aba_mrpc_true_false.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "aba_mrpc_true_false.dev.v0",
            "base_eval": "aba_mrpc_true_false",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "aba_mrpc_true_false/samples.jsonl"
                    },
                    "key": "aba_mrpc_true_false.dev.v0",
                    "group": "aba-mrpc-true-false"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204619UGZMOINH",
            "created_at": "2023-05-14 20:46:19.387387"
        },
        "final_report": {
            "accuracy": 0.8
        }
    },
    "rucola.test.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "rucola.test.v0",
            "base_eval": "rucola",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rucola/samples.jsonl",
                        "few_shot_jsonl": "rucola/few_shot.jsonl",
                        "num_few_shot": 4
                    },
                    "key": "rucola.test.v0",
                    "group": "rucola"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202951ELBHLSB7",
            "created_at": "2023-05-14 20:29:51.819106"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "russe.test.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "russe.test.v0",
            "base_eval": "russe",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russe/samples.jsonl",
                        "few_shot_jsonl": "russe/few_shot.jsonl",
                        "num_few_shot": 2
                    },
                    "key": "russe.test.v0",
                    "group": "russe"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204834D6YU5K5K",
            "created_at": "2023-05-14 20:48:34.215024"
        },
        "final_report": {
            "accuracy": 0.7
        }
    },
    "naughty_strings_graded_meta.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "naughty_strings_graded_meta.test.v1",
            "base_eval": "naughty_strings_graded_meta",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "naughty_strings/security.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "security",
                        "metaeval": true
                    },
                    "key": "naughty_strings_graded_meta.test.v1",
                    "group": "naughty_strings"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305141959397AWWPFQF",
            "created_at": "2023-05-14 19:59:39.321860"
        },
        "final_report": {
            "counts/Yes": 10,
            "counts/No": 7,
            "counts/Unsure": 3,
            "score": 0.575,
            "metascore": 0.0
        }
    },
    "knot-theory-code-conversion.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "knot-theory-code-conversion.dev.v0",
            "base_eval": "knot-theory-code-conversion",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "knot-theory/knot-theory-code-conversions.jsonl"
                    },
                    "key": "knot-theory-code-conversion.dev.v0",
                    "group": "knot-theory"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205900OAMAFFF5",
            "created_at": "2023-05-14 20:59:00.432387"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "tempo_to_measure_count.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "tempo_to_measure_count.dev.v0",
            "base_eval": "tempo_to_measure_count",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "tempo_to_measure_count/samples.jsonl"
                    },
                    "key": "tempo_to_measure_count.dev.v0",
                    "group": "tempo_to_measure_count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142012153YHPZIOU",
            "created_at": "2023-05-14 20:12:15.620651"
        },
        "final_report": {
            "accuracy": 0.1,
            "f1_score": 0.02261904761904762
        }
    },
    "first-letters.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "first-letters.dev.v0",
            "base_eval": "first-letters",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "first-letters/samples.jsonl"
                    },
                    "key": "first-letters.dev.v0",
                    "group": "first-letters"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220457WVLCNO6K",
            "created_at": "2023-05-14 22:04:57.150643"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "stock-options-iron-condor-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-options-iron-condor-spread.dev.v0",
            "base_eval": "stock-options-iron-condor-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_iron_condor_spread.jsonl"
                    },
                    "key": "stock-options-iron-condor-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205513KJWEEWOB",
            "created_at": "2023-05-14 20:55:13.878202"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "partially_solved_crossword_clues.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "partially_solved_crossword_clues.dev.v0",
            "base_eval": "partially_solved_crossword_clues",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "partially_solved_crossword_clues/samples.jsonl"
                    },
                    "key": "partially_solved_crossword_clues.dev.v0",
                    "group": "partially_solved_crossword_clues"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202654AK5ACZRA",
            "created_at": "2023-05-14 20:26:54.931509"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "qa.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "qa.dev.v0",
            "base_eval": "qa",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "qa/q_and_a.jsonl"
                    },
                    "key": "qa.dev.v0",
                    "group": "qa"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514200856LVYT4XPO",
            "created_at": "2023-05-14 20:08:56.886882"
        },
        "final_report": {
            "accuracy": 0.55
        }
    },
    "rot13.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "rot13.s1.simple-v0",
            "base_eval": "rot13",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rot13/rot13.jsonl"
                    },
                    "key": "rot13.s1.simple-v0",
                    "group": "rot13"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202707CR2J5XFA",
            "created_at": "2023-05-14 20:27:07.924516"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "imperial_date_to_string.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "imperial_date_to_string.dev.v0",
            "base_eval": "imperial_date_to_string",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "imperial_date_to_string/samples.jsonl"
                    },
                    "key": "imperial_date_to_string.dev.v0",
                    "group": "imperial_date_to_string"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142001177TCHDO42",
            "created_at": "2023-05-14 20:01:17.963633"
        },
        "final_report": {
            "accuracy": 0.7
        }
    },
    "last-word-nth.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "last-word-nth.s1.simple-v0",
            "base_eval": "last-word-nth",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "last_word_nth/samples.jsonl"
                    },
                    "key": "last-word-nth.s1.simple-v0",
                    "group": "last-word-nth"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514221348YWBOBEPH",
            "created_at": "2023-05-14 22:13:48.888340"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "coqa-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "coqa-fact.dev.v0",
            "base_eval": "coqa-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "coqa-fact.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514201705LCMHF3GT",
            "created_at": "2023-05-14 20:17:05.585880"
        },
        "final_report": {
            "counts/A": 6,
            "counts/B": 2,
            "counts/E": 1
        }
    },
    "job_listing_title_for_a_caregiver_in_japan.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "job_listing_title_for_a_caregiver_in_japan.test.v1",
            "base_eval": "job_listing_title_for_a_caregiver_in_japan",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "job_listing_title_for_a_caregiver_in_japan/samples.jsonl"
                    },
                    "key": "job_listing_title_for_a_caregiver_in_japan.test.v1",
                    "group": "job_listing_title_for_a_caregiver_in_japan"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220713NO7SJTI7",
            "created_at": "2023-05-14 22:07:13.735597"
        },
        "final_report": {
            "accuracy": 0.6
        }
    },
    "diversity.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "diversity.dev.v0",
            "base_eval": "diversity",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "diversity",
                        "multicomp_n": 4,
                        "sample_kwargs": {
                            "temperature": 0.4
                        }
                    },
                    "key": "diversity.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210431MEYQRE4B",
            "created_at": "2023-05-14 21:04:31.045290"
        },
        "final_report": {
            "counts/No": 8,
            "counts/Yes": 2,
            "score": 0.2
        }
    },
    "balance-chemical-equation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "balance-chemical-equation.dev.v0",
            "base_eval": "balance-chemical-equation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "balance_chemical_equation/samples.jsonl"
                    },
                    "key": "balance-chemical-equation.dev.v0",
                    "group": "balance-chemical-equation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514204845DBE6P3XI",
            "created_at": "2023-05-14 20:48:45.148954"
        },
        "final_report": {
            "accuracy": 0.45
        }
    },
    "naughty_strings_fuzzy.test.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "naughty_strings_fuzzy.test.v1",
            "base_eval": "naughty_strings_fuzzy",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "naughty_strings/samples.jsonl"
                    },
                    "key": "naughty_strings_fuzzy.test.v1",
                    "group": "naughty_strings"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305141957067CVKLE7Z",
            "created_at": "2023-05-14 19:57:06.406144"
        },
        "final_report": {
            "accuracy": 0.75,
            "f1_score": 0.75
        }
    },
    "us-tort-law.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "us-tort-law.dev.v0",
            "base_eval": "us-tort-law",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "few_shot_jsonl": "us_tort_law/few_shot.jsonl",
                        "num_few_shot": 4,
                        "samples_jsonl": "us_tort_law/samples.jsonl"
                    },
                    "key": "us-tort-law.dev.v0",
                    "group": "us-tort-law"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051421441062LZFVQW",
            "created_at": "2023-05-14 21:44:10.843441"
        },
        "final_report": {
            "accuracy": 0.65
        }
    },
    "greek-vocabulary.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "greek-vocabulary.dev.v0",
            "base_eval": "greek-vocabulary",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "greek_vocabulary/samples.jsonl"
                    },
                    "key": "greek-vocabulary.dev.v0",
                    "group": "greek-vocabulary"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220644CI7QFXWB",
            "created_at": "2023-05-14 22:06:44.636771"
        },
        "final_report": {
            "accuracy": 0.8
        }
    },
    "forth-stack-sim-detailed.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "forth-stack-sim-detailed.dev.v0",
            "base_eval": "forth-stack-sim-detailed",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/detailed_samples.jsonl"
                    },
                    "key": "forth-stack-sim-detailed.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305142025415AVL6SYG",
            "created_at": "2023-05-14 20:25:41.818350"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "connect4.s1.v1.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "connect4.s1.v1",
            "base_eval": "connect4",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "connect4/samples.jsonl"
                    },
                    "key": "connect4.s1.v1",
                    "group": "connect-4"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514220253TV2XS56V",
            "created_at": "2023-05-14 22:02:53.634916"
        },
        "final_report": {
            "accuracy": 0.3
        }
    },
    "ph-calculation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "ph-calculation.dev.v0",
            "base_eval": "ph-calculation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "ph_calculation/samples.jsonl"
                    },
                    "key": "ph-calculation.dev.v0",
                    "group": "ph_calculation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514221325UBJ72IAD",
            "created_at": "2023-05-14 22:13:25.984238"
        },
        "final_report": {
            "accuracy": 0.2,
            "f1_score": 0.0875
        }
    },
    "stock-options-bull-call-spread.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "stock-options-bull-call-spread.dev.v0",
            "base_eval": "stock-options-bull-call-spread",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "stock_options/stock_options_bull_call_spread.jsonl"
                    },
                    "key": "stock-options-bull-call-spread.dev.v0",
                    "group": "stock-options"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514205443Z6KWXF6W",
            "created_at": "2023-05-14 20:54:43.382046"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "rap-people-vs-people.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "rap-people-vs-people.dev.v0",
            "base_eval": "rap-people-vs-people",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_people_vs_people.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-people-vs-people.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514211505SLY5SZHI",
            "created_at": "2023-05-14 21:15:05.536793"
        },
        "final_report": {
            "counts/No": 4,
            "counts/Yes": 5,
            "score": 0.5555555555555556
        }
    },
    "forth-stack-sim.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "forth-stack-sim.dev.v0",
            "base_eval": "forth-stack-sim",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "forth_stack_sim/samples.jsonl"
                    },
                    "key": "forth-stack-sim.dev.v0",
                    "group": "forth-stack-sim"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514202452RBCZL4S3",
            "created_at": "2023-05-14 20:24:52.115030"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "heart-disease.v0.json": {
        "spec": {
            "completion_fns": [
                "gpt-3.5-turbo"
            ],
            "eval_name": "heart-disease.v0",
            "base_eval": "heart-disease",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "gpt-3.5-turbo"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "heart-disease/samples.jsonl"
                    },
                    "key": "heart-disease.v0",
                    "group": "heart-disease"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230514210846WKOKSV6D",
            "created_at": "2023-05-14 21:08:46.887168"
        },
        "final_report": {
            "accuracy": 0.85
        }
    }
}