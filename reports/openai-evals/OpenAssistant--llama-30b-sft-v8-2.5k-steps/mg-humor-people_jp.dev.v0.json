{"spec": {"completion_fns": ["open-assistant:OpenAssistant/llama-30b-sft-v8-2.5k-steps", "openai:gpt-3.5-turbo-0301"], "eval_name": "mg-humor-people_jp.dev.v0", "base_eval": "mg-humor-people_jp", "split": "dev", "run_config": {"completion_fns": ["open-assistant:OpenAssistant/llama-30b-sft-v8-2.5k-steps", "openai:gpt-3.5-turbo-0301"], "eval_spec": {"cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify", "args": {"samples_jsonl": "test_modelgraded/humor_people_jp.jsonl", "eval_type": "cot_classify_jp", "modelgraded_spec": "humor_jp"}, "key": "mg-humor-people_jp.dev.v0", "group": "test-modelgraded-generated"}, "seed": 20220722, "max_samples": null, "command": "./evaluate.py -e -m open-assistant:OpenAssistant/llama-30b-sft-v8-2.5k-steps -b openai-evals", "initial_settings": {"visible": true}}, "created_by": "", "run_id": "230618190519MHRJPLJU", "created_at": "2023-06-18 19:05:19.833740"}}
{"final_report": {"counts/2": 6, "counts/__invalid__": 1, "counts/1": 9, "counts/4": 1, "counts/3": 3, "score": 1.75}}
