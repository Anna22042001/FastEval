{"spec": {"completion_fns": ["open-assistant:OpenAssistant/oasst-sft-7e3-llama-30b"], "eval_name": "moral_exceptQA.test.v1", "base_eval": "moral_exceptQA", "split": "test", "run_config": {"completion_fns": ["open-assistant:OpenAssistant/oasst-sft-7e3-llama-30b"], "eval_spec": {"cls": "evals.elsuite.basic.match:Match", "args": {"samples_jsonl": "moral_exceptQA/samples.jsonl"}, "key": "moral_exceptQA.test.v1", "group": "moral_exceptQA"}, "seed": 20220722, "max_samples": null, "command": "./evaluate.py -e -m open-assistant:OpenAssistant/oasst-sft-7e3-llama-30b", "initial_settings": {"visible": true}}, "created_by": "", "run_id": "230618181702Q5TM5ES5", "created_at": "2023-06-18 18:17:02.514512"}}
{"final_report": {"accuracy": 0.85}}
