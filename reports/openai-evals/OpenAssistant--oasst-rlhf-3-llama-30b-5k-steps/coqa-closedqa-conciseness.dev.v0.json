{"spec": {"completion_fns": ["open-assistant:OpenAssistant/oasst-rlhf-3-llama-30b-5k-steps", "openai:gpt-3.5-turbo"], "eval_name": "coqa-closedqa-conciseness.dev.v0", "base_eval": "coqa-closedqa-conciseness", "split": "dev", "run_config": {"completion_fns": ["open-assistant:OpenAssistant/oasst-rlhf-3-llama-30b-5k-steps", "openai:gpt-3.5-turbo"], "eval_spec": {"cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify", "args": {"samples_jsonl": "coqa/samples.jsonl", "modelgraded_spec": "closedqa", "modelgraded_spec_args": {"criteria": "conciseness: Is the answer concise and to the point?"}}, "key": "coqa-closedqa-conciseness.dev.v0", "group": "coqa-ex"}, "seed": 20220722, "max_samples": null, "command": "./evaluate.py -e -m open-assistant:OpenAssistant/oasst-rlhf-3-llama-30b-5k-steps -b openai-evals", "initial_settings": {"visible": true}}, "created_by": "", "run_id": "230618181115XM6AI2OG", "created_at": "2023-06-18 18:11:15.841003"}}
{"final_report": {"counts/Y": 4, "counts/N": 5, "score": 0.4444444444444444}}
