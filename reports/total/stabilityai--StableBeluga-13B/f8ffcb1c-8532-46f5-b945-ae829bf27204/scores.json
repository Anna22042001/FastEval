{
    "cot": 0.2969338804527659,
    "human-eval-plus": 0.1951219512195122,
    "lm-evaluation-harness": 71.30944751863265,
    "mt-bench": 6.19375,
    "ds1000": 0.1141170955615981,
    "code": 0.14449391643331588,
    "total": 41.06143734699199
}