{
    "benchmarks": {
        "cot": 0.3603070318100162,
        "human-eval-plus": 0.1951219512195122,
        "lm-evaluation-harness": 0.7130944751863265,
        "mt-bench": 6.19375
    },
    "total": 55.75521223999439
}