{
    "cot": 0.29672530345471526,
    "human-eval-plus": 0.1951219512195122,
    "lm-evaluation-harness": 71.30944751863265,
    "mt-bench": 6.19375,
    "ds1000": 0.1141170955615981,
    "code": 0.14449391643331588,
    "total": 41.05327563837261
}