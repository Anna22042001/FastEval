{
    "cot": 0.3266457024915229,
    "human-eval-plus": 0.2113821138211382,
    "lm-evaluation-harness": 73.92421116065573,
    "mt-bench": 6.634375,
    "ds1000": 0.12064755505263096,
    "code": 0.15467301459082117,
    "total": 44.31686252516083
}