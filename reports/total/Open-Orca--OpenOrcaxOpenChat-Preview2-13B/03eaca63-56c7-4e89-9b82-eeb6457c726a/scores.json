{
    "cot": 0.3106578603371173,
    "human-eval-plus": 0.20528455284552843,
    "lm-evaluation-harness": 72.42375634168857,
    "mt-bench": 6.384375,
    "ds1000": 0.10970958105687616,
    "code": 0.14555019547762077,
    "total": 42.44563706497625
}