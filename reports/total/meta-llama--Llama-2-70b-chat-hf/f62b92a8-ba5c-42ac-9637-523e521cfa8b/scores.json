{
    "cot": 0.35503384932920534,
    "human-eval-plus": 0.29065040650406504,
    "lm-evaluation-harness": 71.53529792832921,
    "mt-bench": 7.1,
    "ds1000": 0.13935658212182495,
    "code": 0.196091766265165,
    "total": 48.17248569140656
}