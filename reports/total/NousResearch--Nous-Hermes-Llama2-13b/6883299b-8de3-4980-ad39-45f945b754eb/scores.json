{
    "benchmarks": {
        "human-eval-plus": 0.21951219512195116,
        "lm-evaluation-harness": 70.0307043942166,
        "mt-bench": 6.5375
    }
}