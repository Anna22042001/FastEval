{
    "benchmarks": {
        "human-eval-plus": 0.09349593495934959,
        "lm-evaluation-harness": 65.83317088393866,
        "mt-bench": 6.109375
    }
}