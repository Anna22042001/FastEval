{
    "cot": 0.20817488820089441,
    "human-eval-plus": 0.09756097560975609,
    "lm-evaluation-harness": 65.2312715225068,
    "mt-bench": 6.06875,
    "ds1000": 0.017631213591809868,
    "code": 0.0476048743485397,
    "total": 35.35975430957482
}