{
    "benchmarks": {
        "human-eval-plus": 0.09756097560975609,
        "lm-evaluation-harness": 60.300566158762216,
        "mt-bench": 5.115625
    }
}