{
    "cot": 0.27892998181728834,
    "human-eval-plus": 0.1260162601626016,
    "lm-evaluation-harness": 70.35287686850494,
    "mt-bench": 6.965625,
    "ds1000": 0.0953057332836834,
    "code": 0.10682218086327772,
    "total": 43.05775460786394
}