{
    "benchmarks": {
        "human-eval-plus": 0.23577235772357721,
        "lm-evaluation-harness": 72.4790335586658,
        "mt-bench": 6.240625
    }
}