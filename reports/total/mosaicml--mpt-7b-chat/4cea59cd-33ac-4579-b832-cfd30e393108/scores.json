{
    "benchmarks": {
        "human-eval-plus": 0.17682926829268292,
        "lm-evaluation-harness": 64.76078622321252,
        "mt-bench": 5.340625
    }
}