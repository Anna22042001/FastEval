{
    "cot": 0.11822835308185883,
    "human-eval-plus": 0.004065040650406503,
    "lm-evaluation-harness": 62.499676950878346,
    "mt-bench": 3.875,
    "ds1000": 0.011485957742804974,
    "code": 0.008703113833155546,
    "total": 21.625511448127614
}