{
    "cot": 0.12214932429111997,
    "human-eval-plus": 0.004065040650406503,
    "lm-evaluation-harness": 62.499676950878346,
    "mt-bench": 3.875,
    "ds1000": 0.011485957742804974,
    "code": 0.008703113833155546,
    "total": 21.778940756316096
}