{
    "cot": 0.22316403754484251,
    "human-eval-plus": 0.1382113821138211,
    "lm-evaluation-harness": 73.94864990263017,
    "mt-bench": 6.303125,
    "ds1000": 0.11188044305285212,
    "code": 0.12175454520071549,
    "total": 38.25486747263671
}