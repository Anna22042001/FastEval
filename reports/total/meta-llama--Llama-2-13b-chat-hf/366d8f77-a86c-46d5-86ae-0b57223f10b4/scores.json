{
    "benchmarks": {
        "human-eval-plus": 0.18292682926829265,
        "lm-evaluation-harness": 68.47612759800032,
        "mt-bench": 6.6625
    }
}