{
    "cot": 0.26445499041721954,
    "human-eval-plus": 0.2865853658536585,
    "lm-evaluation-harness": 69.44732636040673,
    "mt-bench": 6.453125,
    "ds1000": 0.08910972854497977,
    "code": 0.1631630925357343,
    "total": 41.242922973469184
}