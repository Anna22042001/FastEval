{
    "benchmarks": {
        "human-eval-plus": 0.2865853658536585,
        "lm-evaluation-harness": 69.44732636040673,
        "mt-bench": 6.453125
    }
}