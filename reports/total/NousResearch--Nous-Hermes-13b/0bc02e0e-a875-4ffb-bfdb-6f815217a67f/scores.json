{
    "cot": 0.23558269142851188,
    "human-eval-plus": 0.16463414634146337,
    "lm-evaluation-harness": 68.83845301044039,
    "mt-bench": 6.234375,
    "ds1000": 0.09083291968719945,
    "code": 0.11850837968254842,
    "total": 38.385446702551306
}