{
    "balance-chemical-equation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "balance-chemical-equation.dev.v0",
            "base_eval": "balance-chemical-equation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "balance_chemical_equation/samples.jsonl"
                    },
                    "key": "balance-chemical-equation.dev.v0",
                    "group": "balance-chemical-equation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510191120GZST47OU",
            "created_at": "2023-05-10 19:11:20.930126"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "rap-animals-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "rap-animals-vs-fruits.dev.v0",
            "base_eval": "rap-animals-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_animals_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-animals-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510140850SYWRCSZC",
            "created_at": "2023-05-10 14:08:50.966276"
        },
        "final_report": {
            "counts/Yes": 7,
            "counts/No": 1,
            "counts/__invalid__": 1,
            "score": 0.7777777777777778
        }
    },
    "finance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "finance.dev.v0",
            "base_eval": "finance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "finance/credit.jsonl"
                    },
                    "key": "finance.dev.v0",
                    "group": "finance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510162509RKBJRYPB",
            "created_at": "2023-05-10 16:25:09.141519"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "ph-calculation.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "ph-calculation.dev.v0",
            "base_eval": "ph-calculation",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "ph_calculation/samples.jsonl"
                    },
                    "key": "ph-calculation.dev.v0",
                    "group": "ph_calculation"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510163202JCUYUERG",
            "created_at": "2023-05-10 16:32:02.705679"
        },
        "final_report": {
            "accuracy": 0.1,
            "f1_score": 0.0
        }
    },
    "taxes.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "taxes.dev.v0",
            "base_eval": "taxes",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "taxes/samples.jsonl"
                    },
                    "key": "taxes.dev.v0",
                    "group": "taxes"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510152929VTRWM5PI",
            "created_at": "2023-05-10 15:29:29.644317"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "actors-sequence.dev.match-v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "actors-sequence.dev.match-v1",
            "base_eval": "actors-sequence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "actors-sequence/samples.jsonl"
                    },
                    "key": "actors-sequence.dev.match-v1",
                    "group": "actors-sequence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510135127D7YIAIBB",
            "created_at": "2023-05-10 13:51:27.822476"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "belarusian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "belarusian-lexicon.dev.v0",
            "base_eval": "belarusian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "belarusian_lexicon/samples.jsonl"
                    },
                    "key": "belarusian-lexicon.dev.v0",
                    "group": "belarusian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510200401VQRV6ZGF",
            "created_at": "2023-05-10 20:04:01.320944"
        },
        "final_report": {
            "accuracy": 0.45
        }
    },
    "qa.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "qa.dev.v0",
            "base_eval": "qa",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "qa/q_and_a.jsonl"
                    },
                    "key": "qa.dev.v0",
                    "group": "qa"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510195219MFC2FWOY",
            "created_at": "2023-05-10 19:52:19.239790"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "russian-nlp-tasks.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "russian-nlp-tasks.dev.v0",
            "base_eval": "russian-nlp-tasks",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian-nlp-tasks/samples.jsonl"
                    },
                    "key": "russian-nlp-tasks.dev.v0",
                    "group": "russian-nlp-tasks"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510143646BWZP6AQT",
            "created_at": "2023-05-10 14:36:46.917105"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "regex.match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "regex.match.dev.v0",
            "base_eval": "regex",
            "split": "match",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "regex-match/samples.jsonl"
                    },
                    "key": "regex.match.dev.v0",
                    "group": "regex-match"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510135737ERQ2VY5O",
            "created_at": "2023-05-10 13:57:37.679708"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "moral_exceptQA.test.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "moral_exceptQA.test.v1",
            "base_eval": "moral_exceptQA",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "moral_exceptQA/samples.jsonl"
                    },
                    "key": "moral_exceptQA.test.v1",
                    "group": "moral_exceptQA"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510163847Z623RJIM",
            "created_at": "2023-05-10 16:38:47.594202"
        },
        "final_report": {
            "accuracy": 0.15
        }
    },
    "anagrams.test.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "anagrams.test.v1",
            "base_eval": "anagrams",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "few_shot_jsonl": "anagrams/fewshot.jsonl",
                        "num_few_shot": 5,
                        "samples_jsonl": "anagrams/samples.jsonl"
                    },
                    "key": "anagrams.test.v1",
                    "group": "anagrams"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510193339CKKYFUJH",
            "created_at": "2023-05-10 19:33:39.515864"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "number-reading.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "number-reading.dev.v0",
            "base_eval": "number-reading",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "number_reading/number_reading.jsonl"
                    },
                    "key": "number-reading.dev.v0",
                    "group": "number-reading"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510194357J5HPL3GW",
            "created_at": "2023-05-10 19:43:57.188634"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "infiniteloop-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "infiniteloop-match.s1.simple-v0",
            "base_eval": "infiniteloop-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "infiniteloop-match/infiniteloop-match.jsonl"
                    },
                    "key": "infiniteloop-match.s1.simple-v0",
                    "group": "infiniteloop-match"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510165911XIVVG4SD",
            "created_at": "2023-05-10 16:59:11.107523"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "connect4.s1.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "connect4.s1.v1",
            "base_eval": "connect4",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "connect4/samples.jsonl"
                    },
                    "key": "connect4.s1.v1",
                    "group": "connect-4"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101710446WDXNPSA",
            "created_at": "2023-05-10 17:10:44.346511"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "coqa-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-fact.dev.v0",
            "base_eval": "coqa-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "coqa-fact.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101217592UIUJ3RO",
            "created_at": "2023-05-10 12:17:59.770339"
        },
        "final_report": {
            "counts/B": 1,
            "counts/A": 4,
            "counts/__invalid__": 2,
            "counts/D": 1,
            "counts/E": 1
        }
    },
    "rap-people-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "rap-people-vs-fruits.dev.v0",
            "base_eval": "rap-people-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_people_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-people-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510141831HJQGDTLX",
            "created_at": "2023-05-10 14:18:31.676797"
        },
        "final_report": {
            "counts/Yes": 6,
            "counts/No": 3,
            "score": 0.6666666666666666
        }
    },
    "utility_price_parsing.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "utility_price_parsing.dev.v0",
            "base_eval": "utility_price_parsing",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "utility_price_parsing/samples.jsonl"
                    },
                    "key": "utility_price_parsing.dev.v0",
                    "group": "utility_price_parsing"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510185100XBJKVIFD",
            "created_at": "2023-05-10 18:51:00.099073"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "cube-pack.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "cube-pack.dev.v0",
            "base_eval": "cube-pack",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "cube-pack/samples.jsonl"
                    },
                    "key": "cube-pack.dev.v0",
                    "group": "cube-pack"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101819455P3CBSYM",
            "created_at": "2023-05-10 18:19:45.363521"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "bulgarian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "bulgarian-lexicon.dev.v0",
            "base_eval": "bulgarian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bulgarian-lexicon/samples.jsonl"
                    },
                    "key": "bulgarian-lexicon.dev.v0",
                    "group": "bulgarian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "23051017263837VQ3WOB",
            "created_at": "2023-05-10 17:26:38.050832"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "sort-numbers.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "sort-numbers.s1.simple-v0",
            "base_eval": "sort-numbers",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "sort_numeric/samples.jsonl"
                    },
                    "key": "sort-numbers.s1.simple-v0",
                    "group": "sort-numeric"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510174842Z5FSQN26",
            "created_at": "2023-05-10 17:48:42.478860"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "swedish-spelling.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "swedish-spelling.dev.v0",
            "base_eval": "swedish-spelling",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "swedish-spelling/samples.jsonl"
                    },
                    "key": "swedish-spelling.dev.v0",
                    "group": "swedish-spelling"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510152215K52GUKTO",
            "created_at": "2023-05-10 15:22:15.639130"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "match_banking77.test.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "match_banking77.test.v1",
            "base_eval": "match_banking77",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "banking77/samples.jsonl"
                    },
                    "key": "match_banking77.test.v1",
                    "group": "banking77"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510144556DJHESDZ6",
            "created_at": "2023-05-10 14:45:56.386177"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "hand_ranks.test.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "hand_ranks.test.v1",
            "base_eval": "hand_ranks",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "poker_hand_ranks/full_samples.jsonl"
                    },
                    "key": "hand_ranks.test.v1",
                    "group": "poker_hand_ranks"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510152608NYQIIIM4",
            "created_at": "2023-05-10 15:26:08.203171"
        },
        "final_report": {
            "accuracy": 0.15
        }
    },
    "mendelian_inheritance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "mendelian_inheritance.dev.v0",
            "base_eval": "mendelian_inheritance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "mendelian_inheritance/samples.jsonl"
                    },
                    "key": "mendelian_inheritance.dev.v0",
                    "group": "mendelian_inheritance"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510184628BEL54AG3",
            "created_at": "2023-05-10 18:46:28.120259"
        },
        "final_report": {
            "accuracy": 0.0625
        }
    },
    "coqa-closedqa-conciseness.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-closedqa-conciseness.dev.v0",
            "base_eval": "coqa-closedqa-conciseness",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "conciseness: Is the answer concise and to the point?"
                        }
                    },
                    "key": "coqa-closedqa-conciseness.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510124053ILHCFKZJ",
            "created_at": "2023-05-10 12:40:53.187141"
        },
        "final_report": {
            "counts/Y": 4,
            "counts/N": 5,
            "score": 0.4444444444444444
        }
    },
    "emotional-intelligence.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "emotional-intelligence.dev.v0",
            "base_eval": "emotional-intelligence",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "emotional-intelligence/samples.jsonl"
                    },
                    "key": "emotional-intelligence.dev.v0",
                    "group": "emotional-intelligence"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510155012NXT3G3BJ",
            "created_at": "2023-05-10 15:50:12.936347"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "joke-fruits-expl-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits-expl-meta.dev.v0",
            "base_eval": "joke-fruits-expl-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "classify_cot",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-expl-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510113824XFCBMB5P",
            "created_at": "2023-05-10 11:38:24.450983"
        },
        "final_report": {
            "counts/Yes": 10,
            "score": 1.0,
            "metascore": 0.5
        }
    },
    "pattern_identification.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "pattern_identification.dev.v0",
            "base_eval": "pattern_identification",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "pattern_identification/samples.v0.jsonl"
                    },
                    "key": "pattern_identification.dev.v0",
                    "group": "pattern_identification"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510133930WVBSJJWR",
            "created_at": "2023-05-10 13:39:30.404088"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "joke-animals-vs-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-animals-vs-fruits.dev.v0",
            "base_eval": "joke-animals-vs-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/joke_animals_vs_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "joke-animals-vs-fruits.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510115519SNRCJ5ND",
            "created_at": "2023-05-10 11:55:19.018644"
        },
        "final_report": {
            "counts/Yes": 9,
            "score": 1.0
        }
    },
    "test-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "test-match.s1.simple-v0",
            "base_eval": "test-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_match/samples.jsonl"
                    },
                    "key": "test-match.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510121136YKWL33E7",
            "created_at": "2023-05-10 12:11:36.372019"
        },
        "final_report": {
            "accuracy": 0.6666666666666666
        }
    },
    "joke-fruits-likert.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits-likert.dev.v0",
            "base_eval": "joke-fruits-likert",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor_likert"
                    },
                    "key": "joke-fruits-likert.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510113012RODNOJR4",
            "created_at": "2023-05-10 11:30:12.684624"
        },
        "final_report": {
            "counts/__invalid__": 2,
            "counts/3": 3,
            "counts/1": 2,
            "counts/5": 1,
            "counts/2": 2,
            "score": 2.2
        }
    },
    "loss-logic-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "loss-logic-fact.dev.v0",
            "base_eval": "loss-logic-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "loss_logic/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "loss-logic-fact.dev.v0",
                    "group": "loss-logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510185418UNRBN43S",
            "created_at": "2023-05-10 18:54:18.632051"
        },
        "final_report": {
            "counts/A": 1,
            "counts/E": 2,
            "counts/D": 2
        }
    },
    "computer-science-problems.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "computer-science-problems.s1.simple-v0",
            "base_eval": "computer-science-problems",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "test_comp_sci/questions.jsonl"
                    },
                    "key": "computer-science-problems.s1.simple-v0",
                    "group": "test-comp-sci"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510160951WT2RYFAC",
            "created_at": "2023-05-10 16:09:51.802456"
        },
        "final_report": {
            "accuracy": 0.25
        }
    },
    "escher-sentences.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "escher-sentences.dev.v0",
            "base_eval": "escher-sentences",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "escher_sentences/samples.jsonl"
                    },
                    "key": "escher-sentences.dev.v0",
                    "group": "escher-sentences"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101719284OJ3N7DI",
            "created_at": "2023-05-10 17:19:28.416782"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "bitwise.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "bitwise.dev.v0",
            "base_eval": "bitwise",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bitwise/samples.jsonl"
                    },
                    "key": "bitwise.dev.v0",
                    "group": "bitwise"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101402105N7BS6AH",
            "created_at": "2023-05-10 14:02:10.431377"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "partially_solved_crossword_clues.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "partially_solved_crossword_clues.dev.v0",
            "base_eval": "partially_solved_crossword_clues",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "partially_solved_crossword_clues/samples.jsonl"
                    },
                    "key": "partially_solved_crossword_clues.dev.v0",
                    "group": "partially_solved_crossword_clues"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510184107ZKSXVT3I",
            "created_at": "2023-05-10 18:41:07.719510"
        },
        "final_report": {
            "accuracy": 0.05
        }
    },
    "which-is-heavier.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "which-is-heavier.dev.v0",
            "base_eval": "which-is-heavier",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "which_is_heavier/which_is_heavier.jsonl"
                    },
                    "key": "which-is-heavier.dev.v0",
                    "group": "which-is-heavier"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510180858SUTIT7T7",
            "created_at": "2023-05-10 18:08:58.207328"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "joke-fruits-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits-meta.dev.v0",
            "base_eval": "joke-fruits-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510113525FDD73NDC",
            "created_at": "2023-05-10 11:35:25.807945"
        },
        "final_report": {
            "counts/Unsure": 1,
            "counts/Yes": 6,
            "counts/No": 3,
            "score": 0.65,
            "metascore": 0.5
        }
    },
    "convert-hex-hsl-lightness.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "convert-hex-hsl-lightness.dev.v0",
            "base_eval": "convert-hex-hsl-lightness",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "convert-hex-hsl-lightness/samples.jsonl"
                    },
                    "key": "convert-hex-hsl-lightness.dev.v0",
                    "group": "convert-hex-hsl-lightness"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101930452IR7KUMZ",
            "created_at": "2023-05-10 19:30:45.778209"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "russe.test.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "russe.test.v0",
            "base_eval": "russe",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russe/samples.jsonl",
                        "few_shot_jsonl": "russe/few_shot.jsonl",
                        "num_few_shot": 2
                    },
                    "key": "russe.test.v0",
                    "group": "russe"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510175653MYRUBCBD",
            "created_at": "2023-05-10 17:56:53.894842"
        },
        "final_report": {
            "accuracy": 0.6
        }
    },
    "joke-fruits-v2.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits-v2.dev.v0",
            "base_eval": "joke-fruits-v2",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor_out_message"
                    },
                    "key": "joke-fruits-v2.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510112346I7ILD4A2",
            "created_at": "2023-05-10 11:23:46.119493"
        },
        "final_report": {
            "counts/Yes": 3,
            "counts/No": 5,
            "counts/Unsure": 2,
            "score": 0.4
        }
    },
    "number-pattern.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "number-pattern.dev.v0",
            "base_eval": "number-pattern",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "number_pattern/samples.jsonl"
                    },
                    "key": "number-pattern.dev.v0",
                    "group": "number-pattern"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510190449KTDAU2SD",
            "created_at": "2023-05-10 19:04:49.386981"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "lat_long_identify.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "lat_long_identify.dev.v0",
            "base_eval": "lat_long_identify",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "lat_long_identify/samples.jsonl"
                    },
                    "key": "lat_long_identify.dev.v0",
                    "group": "lat_long_identify"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101626516Y3F5PEG",
            "created_at": "2023-05-10 16:26:51.989247"
        },
        "final_report": {
            "accuracy": 0.15
        }
    },
    "first-letters.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "first-letters.dev.v0",
            "base_eval": "first-letters",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "first-letters/samples.jsonl"
                    },
                    "key": "first-letters.dev.v0",
                    "group": "first-letters"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101620185JGDIHBL",
            "created_at": "2023-05-10 16:20:18.654753"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "invoices.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "invoices.dev.v0",
            "base_eval": "invoices",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "invoices/match.jsonl"
                    },
                    "key": "invoices.dev.v0",
                    "group": "invoices"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510144848IEUACBNN",
            "created_at": "2023-05-10 14:48:48.865045"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "coqa-match.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-match.dev.v0",
            "base_eval": "coqa-match",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "coqa/match.jsonl"
                    },
                    "key": "coqa-match.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510121631MQJBMRES",
            "created_at": "2023-05-10 12:16:31.124516"
        },
        "final_report": {
            "accuracy": 0.6
        }
    },
    "coqa-closedqa-correct.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-closedqa-correct.dev.v0",
            "base_eval": "coqa-closedqa-correct",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "correctness: Is the answer correct?"
                        }
                    },
                    "key": "coqa-closedqa-correct.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510122930FDCLSOWG",
            "created_at": "2023-05-10 12:29:30.316776"
        },
        "final_report": {
            "counts/N": 4,
            "counts/Y": 5,
            "score": 0.5555555555555556
        }
    },
    "logic-statements.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "logic-statements.dev.v0",
            "base_eval": "logic-statements",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "logic-statements/logic-statements.jsonl"
                    },
                    "key": "logic-statements.dev.v0",
                    "group": "logic-statements"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101510172HJ72OGT",
            "created_at": "2023-05-10 15:10:17.054713"
        },
        "final_report": {
            "accuracy": 0.25,
            "f1_score": 0.06428571428571428
        }
    },
    "test-fuzzy-match.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "test-fuzzy-match.s1.simple-v0",
            "base_eval": "test-fuzzy-match",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl"
                    },
                    "key": "test-fuzzy-match.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510121249XC7A4DNJ",
            "created_at": "2023-05-10 12:12:49.017259"
        },
        "final_report": {
            "accuracy": 0.6666666666666666,
            "f1_score": 0.42083333333333334
        }
    },
    "russian_medical.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "russian_medical.dev.v0",
            "base_eval": "russian_medical",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "russian_medical/samples.jsonl"
                    },
                    "key": "russian_medical.dev.v0",
                    "group": "russian_medical"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510190935W4ETMQ7J",
            "created_at": "2023-05-10 19:09:35.350197"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "diversity.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "diversity.dev.v0",
            "base_eval": "diversity",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "diversity",
                        "multicomp_n": 4,
                        "sample_kwargs": {
                            "temperature": 0.4
                        }
                    },
                    "key": "diversity.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510114152ZRDOKSJN",
            "created_at": "2023-05-10 11:41:52.346343"
        },
        "final_report": {
            "counts/Yes": 10,
            "score": 1.0
        }
    },
    "formal-logic.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "formal-logic.dev.v0",
            "base_eval": "formal-logic",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "formal_logic/formal_logic_expressions.jsonl"
                    },
                    "key": "formal-logic.dev.v0",
                    "group": "formal_logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510151838K2NAE2UE",
            "created_at": "2023-05-10 15:18:38.466121"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "compare-countries-area.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "compare-countries-area.dev.v0",
            "base_eval": "compare-countries-area",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "compare-countries-area/samples.jsonl"
                    },
                    "key": "compare-countries-area.dev.v0",
                    "group": "compare-countries-area"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510191734E6CBVOQZ",
            "created_at": "2023-05-10 19:17:34.675736"
        },
        "final_report": {
            "accuracy": 0.35
        }
    },
    "map-electronic-component-part-to-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "map-electronic-component-part-to-fact.dev.v0",
            "base_eval": "map-electronic-component-part-to-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "map-electronic-component-part-to-fact/samples.jsonl"
                    },
                    "key": "map-electronic-component-part-to-fact.dev.v0",
                    "group": "map-electronic-component-part-to-fact"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510182718MHGOG7FQ",
            "created_at": "2023-05-10 18:27:18.618078"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "crepe.dev.v2.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "crepe.dev.v2",
            "base_eval": "crepe",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "crepe/samples.jsonl"
                    },
                    "key": "crepe.dev.v2",
                    "group": "crepe"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510142835JDOMCLYO",
            "created_at": "2023-05-10 14:28:35.022279"
        },
        "final_report": {
            "accuracy": 0.1
        }
    },
    "test-includes.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "test-includes.s1.simple-v0",
            "base_eval": "test-includes",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl"
                    },
                    "key": "test-includes.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510121359BMFDCZ3Q",
            "created_at": "2023-05-10 12:13:59.955904"
        },
        "final_report": {
            "accuracy": 1.0
        }
    },
    "joke-fruits-ans-meta.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits-ans-meta.dev.v0",
            "base_eval": "joke-fruits-ans-meta",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_metaeval/joke_fruits_labeled.jsonl",
                        "eval_type": "classify",
                        "modelgraded_spec": "humor",
                        "metaeval": true
                    },
                    "key": "joke-fruits-ans-meta.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510133601B4QIX4OK",
            "created_at": "2023-05-10 13:36:01.548139"
        },
        "final_report": {
            "counts/Yes": 10,
            "score": 1.0,
            "metascore": 0.5
        }
    },
    "job_listing_title_for_a_caregiver_in_japan.test.v1.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "job_listing_title_for_a_caregiver_in_japan.test.v1",
            "base_eval": "job_listing_title_for_a_caregiver_in_japan",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "job_listing_title_for_a_caregiver_in_japan/samples.jsonl"
                    },
                    "key": "job_listing_title_for_a_caregiver_in_japan.test.v1",
                    "group": "job_listing_title_for_a_caregiver_in_japan"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101506042SHYBIG2",
            "created_at": "2023-05-10 15:06:04.909710"
        },
        "final_report": {
            "accuracy": 0.13333333333333333
        }
    },
    "rap-people-vs-people.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "rap-people-vs-people.dev.v0",
            "base_eval": "rap-people-vs-people",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_multiio/battles/rap_people_vs_people.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "battle"
                    },
                    "key": "rap-people-vs-people.dev.v0",
                    "group": "test-modelgraded-battle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510120150HPXPOSPV",
            "created_at": "2023-05-10 12:01:50.810526"
        },
        "final_report": {
            "counts/Yes": 9,
            "score": 1.0
        }
    },
    "logic-fact.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "logic-fact.dev.v0",
            "base_eval": "logic-fact",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "logic/samples.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "fact"
                    },
                    "key": "logic-fact.dev.v0",
                    "group": "logic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510124610YKPNHBRH",
            "created_at": "2023-05-10 12:46:10.235013"
        },
        "final_report": {
            "counts/A": 6,
            "counts/B": 1,
            "counts/E": 3
        }
    },
    "chess-piece-count.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "chess-piece-count.s1.simple-v0",
            "base_eval": "chess-piece-count",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "chess_piece_count/fuzzy_match.jsonl"
                    },
                    "key": "chess-piece-count.s1.simple-v0",
                    "group": "chess-piece-count"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101455244ZBLE3CC",
            "created_at": "2023-05-10 14:55:24.896728"
        },
        "final_report": {
            "accuracy": 0.0,
            "f1_score": 0.0
        }
    },
    "rot13.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "rot13.s1.simple-v0",
            "base_eval": "rot13",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rot13/rot13.jsonl"
                    },
                    "key": "rot13.s1.simple-v0",
                    "group": "rot13"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510150201B4Y2FBDB",
            "created_at": "2023-05-10 15:02:01.572578"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "hindi_upsc.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "hindi_upsc.dev.v0",
            "base_eval": "hindi_upsc",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "hindi_upsc/samples.jsonl"
                    },
                    "key": "hindi_upsc.dev.v0",
                    "group": "hindi_upsc"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510181508SBSFUS6Q",
            "created_at": "2023-05-10 18:15:08.752881"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "brazilian-lexicon.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "brazilian-lexicon.dev.v0",
            "base_eval": "brazilian-lexicon",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "brazilian-lexicon/samples.jsonl"
                    },
                    "key": "brazilian-lexicon.dev.v0",
                    "group": "brazilian-lexicon"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510192427IKOWTMQM",
            "created_at": "2023-05-10 19:24:27.236323"
        },
        "final_report": {
            "accuracy": 0.4
        }
    },
    "test-includes-ignore-case.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "test-includes-ignore-case.s1.simple-v0",
            "base_eval": "test-includes-ignore-case",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.includes:Includes",
                    "args": {
                        "samples_jsonl": "test_fuzzy_match/samples.jsonl",
                        "ignore_case": true
                    },
                    "key": "test-includes-ignore-case.s1.simple-v0",
                    "group": "test-basic"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510121515TNTW4GB4",
            "created_at": "2023-05-10 12:15:15.262490"
        },
        "final_report": {
            "accuracy": 0.6666666666666666
        }
    },
    "fcc_amateur_extra.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "fcc_amateur_extra.dev.v0",
            "base_eval": "fcc_amateur_extra",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "fcc_amateur_extra/samples.jsonl"
                    },
                    "key": "fcc_amateur_extra.dev.v0",
                    "group": "fcc_amateur_extra"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510193740A5LL3A6M",
            "created_at": "2023-05-10 19:37:40.727904"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "reverse-string.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "reverse-string.s1.simple-v0",
            "base_eval": "reverse-string",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "reverse_string/reverse_string.jsonl"
                    },
                    "key": "reverse-string.s1.simple-v0",
                    "group": "reverse-string"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510143442QK5WH2QJ",
            "created_at": "2023-05-10 14:34:42.767025"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "complex-replace-characters.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "complex-replace-characters.dev.v0",
            "base_eval": "complex-replace-characters",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "complex_replace_characters/samples.jsonl"
                    },
                    "key": "complex-replace-characters.dev.v0",
                    "group": "complex-replace-characters"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510144129GYPKTYF5",
            "created_at": "2023-05-10 14:41:29.307840"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "rucola.test.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "rucola.test.v0",
            "base_eval": "rucola",
            "split": "test",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "rucola/samples.jsonl",
                        "few_shot_jsonl": "rucola/few_shot.jsonl",
                        "num_few_shot": 4
                    },
                    "key": "rucola.test.v0",
                    "group": "rucola"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510175148BMOZNDQN",
            "created_at": "2023-05-10 17:51:48.552035"
        },
        "final_report": {
            "accuracy": 0.2
        }
    },
    "simple-knowledge-mongolian.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "simple-knowledge-mongolian.dev.v0",
            "base_eval": "simple-knowledge-mongolian",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "simple-knowledge-mongolian/samples.v0.jsonl"
                    },
                    "key": "simple-knowledge-mongolian.dev.v0",
                    "group": "simple-knowledge-mongolian"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510170352LLUBZYES",
            "created_at": "2023-05-10 17:03:52.296736"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "coqa-fact-expl.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-fact-expl.dev.v0",
            "base_eval": "coqa-fact-expl",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "eval_type": "classify_cot",
                        "modelgraded_spec": "fact"
                    },
                    "key": "coqa-fact-expl.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510122401QTVFS25R",
            "created_at": "2023-05-10 12:24:01.015923"
        },
        "final_report": {
            "counts/B": 5,
            "counts/C": 1,
            "counts/E": 2,
            "counts/A": 1
        }
    },
    "emoji-riddle.s1.simple-v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "emoji-riddle.s1.simple-v0",
            "base_eval": "emoji-riddle",
            "split": "s1",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "emoji_riddle/fuzzy_match.jsonl"
                    },
                    "key": "emoji-riddle.s1.simple-v0",
                    "group": "emoji-riddle"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101615355TM3UFFS",
            "created_at": "2023-05-10 16:15:35.780787"
        },
        "final_report": {
            "accuracy": 0.15,
            "f1_score": 0.07526582278481013
        }
    },
    "japanese-national-medical-exam01.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "japanese-national-medical-exam01.dev.v0",
            "base_eval": "japanese-national-medical-exam01",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "japanese-national-medical-exam01/japanese-national-medical-exam01.jsonl"
                    },
                    "key": "japanese-national-medical-exam01.dev.v0",
                    "group": "japanese-national-medical-exam01"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510171531FVXVR3Z6",
            "created_at": "2023-05-10 17:15:31.314368"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "joke-fruits.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "joke-fruits.dev.v0",
            "base_eval": "joke-fruits",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "test_modelgraded/joke_fruits.jsonl",
                        "eval_type": "cot_classify",
                        "modelgraded_spec": "humor"
                    },
                    "key": "joke-fruits.dev.v0",
                    "group": "test-modelgraded"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510111749XMDFO37Z",
            "created_at": "2023-05-10 11:17:49.853603"
        },
        "final_report": {
            "counts/Yes": 7,
            "counts/No": 1,
            "counts/Unsure": 2,
            "score": 0.8
        }
    },
    "three-pt-mapping.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "three-pt-mapping.dev.v0",
            "base_eval": "three-pt-mapping",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "three-pt-mapping/three_pt_mapping.jsonl"
                    },
                    "key": "three-pt-mapping.dev.v0",
                    "group": "three-pt-mapping"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510183426FXB2SXNK",
            "created_at": "2023-05-10 18:34:26.168032"
        },
        "final_report": {
            "accuracy": 0.0
        }
    },
    "born-first.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "born-first.dev.v0",
            "base_eval": "born-first",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "born_first/born_first.jsonl"
                    },
                    "key": "born-first.dev.v0",
                    "group": "born-first"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "2305101857314XWZDTR4",
            "created_at": "2023-05-10 18:57:31.647079"
        },
        "final_report": {
            "accuracy": 0.5
        }
    },
    "coqa-closedqa-relevance.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "coqa-closedqa-relevance.dev.v0",
            "base_eval": "coqa-closedqa-relevance",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.modelgraded.classify:ModelBasedClassify",
                    "args": {
                        "samples_jsonl": "coqa/samples.jsonl",
                        "modelgraded_spec": "closedqa",
                        "modelgraded_spec_args": {
                            "criteria": "relevance: Is the submission referring to a real quote from the text?"
                        }
                    },
                    "key": "coqa-closedqa-relevance.dev.v0",
                    "group": "coqa-ex"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510123443TD2VEIR4",
            "created_at": "2023-05-10 12:34:43.107832"
        },
        "final_report": {
            "counts/Y": 6,
            "counts/N": 3,
            "score": 0.6666666666666666
        }
    },
    "bigrams.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "bigrams.dev.v0",
            "base_eval": "bigrams",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "bigrams/samples.jsonl"
                    },
                    "key": "bigrams.dev.v0",
                    "group": "bigrams"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510194731U7AL3UON",
            "created_at": "2023-05-10 19:47:31.631638"
        },
        "final_report": {
            "accuracy": 0.15
        }
    },
    "russian-rhyme.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "russian-rhyme.v0",
            "base_eval": "russian-rhyme",
            "split": "v0",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.fuzzy_match:FuzzyMatch",
                    "args": {
                        "samples_jsonl": "russian-rhyme/samples.jsonl"
                    },
                    "key": "russian-rhyme.v0",
                    "group": "russian-rhyme"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510180139IMEJK4LE",
            "created_at": "2023-05-10 18:01:39.186730"
        },
        "final_report": {
            "accuracy": 0.17647058823529413,
            "f1_score": 0.2647058823529412
        }
    },
    "greek-vocabulary.dev.v0.json": {
        "spec": {
            "completion_fns": [
                "oasst_completion_fn"
            ],
            "eval_name": "greek-vocabulary.dev.v0",
            "base_eval": "greek-vocabulary",
            "split": "dev",
            "run_config": {
                "completion_fns": [
                    "oasst_completion_fn"
                ],
                "eval_spec": {
                    "cls": "evals.elsuite.basic.match:Match",
                    "args": {
                        "samples_jsonl": "greek_vocabulary/samples.jsonl"
                    },
                    "key": "greek-vocabulary.dev.v0",
                    "group": "greek-vocabulary"
                },
                "seed": 20220722,
                "max_samples": null,
                "command": "./main.py",
                "initial_settings": {
                    "visible": true
                }
            },
            "created_by": "",
            "run_id": "230510134558M4FWJ6OM",
            "created_at": "2023-05-10 13:45:58.414146"
        },
        "final_report": {
            "accuracy": 0.4
        }
    }
}